# Data_Wrangling
Data wrangling or data "munging" is transforming and mapping data from one "raw" data form into another to make it more appropriate and valuable for analytics. The goal of data wrangling is to provide quality assurance and valuable data. Data analysts spend the majority of their time in the process of data wrangling compared to the actual analysis of the data. The data wrangling process may include further munging, data visualization, data aggregation, and training of a statistical model. Data wrangling steps begin with extracting the data, "munging," and depositing the data into a data sink (Data wrangling, 2022)

# The Project
Real-world data rarely is clean. Using Python, you gather data from various sources and formats, assess its quality and tidiness, and then clean it; This is called data wrangling. You document your wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python. The dataset this project is analyzing and visualizing is the tweet archive of Twitter user @dog_rates, AKA WeRateDogs, a Twitter account that rates people's dogs with funny comments. These ratings have a denominator of 10, and numerators are 10. 11/10, 12/10, 13/10. WeRateDogs downloaded their Twitter archive exclusively for this project. This archive contains primary tweet data (tweet ID, timestamp, text.) for all 5000+ of their tweets as they stood on August 1, 2017 (Anon, 2022). 

Sources:

Anon (2022). Udacity.com. https://learn.udacity.com/nanodegrees/nd002/parts/cd0015/lessons/ls2232/concepts/aa514310-e2cf-43d9-8165-aa6dd3b8472d

Data wrangling. (2022, January 17). Wikipedia. https://en.wikipedia.org/wiki/Data_wrangling


